# ğŸ§  PERG Signal Classifier â€“ ML & Deep Learning

## ğŸ”¬ Automated Detection of Pattern Electroretinogram (PERG) Signal

This project simulates a real-world scenario in **clinical bioinformatics**: the automatic analysis of PERG signals to detect early abnormalities of the optic nerve or retina (e.g., glaucoma, neuropathies).

The goal is to compare **Machine Learning (ML)** and **Deep Learning (DL)** models for use in **AI-assisted triage**.  
It relies on real electrophysiological data (open-source dataset) and follows best practices in traceability, reproducibility, cross-validation, and threshold selection.

---

## ğŸ§ª Data Overview

- **Source**: [PERG-IOBA â€“ PhysioNet (2024)](https://physionet.org/content/perg-ioba-dataset/1.0.0/)
- **Format**: 279 raw signals (RE_1, LE_1), sampled at 300 Hz + clinical metadata (age, sex, diagnosis)
- **Ground truth**: Binary diagnostic labels confirmed by an ophthalmologist (label = 0/1)
- **Distribution**: Pathological prevalence â‰ˆ 2% (realistic, imbalanced)

---

## ğŸ” Feature Engineering (ML)

Classical models use **manually engineered features**:

- Basic statistics: mean, min, max, standard deviation  
- Higher-order moments: skewness, kurtosis  
- Frequency domain: FFT (average magnitude, max power, spectral energy)  
- Metadata: encoded age and sex

---

## âš™ï¸ Modeling

### ğŸ§  Machine Learning:
- Tested models: `Logistic Regression`, `Decision Tree`, `Random Forest`, `XGBoost`
- Input: FFT + time-based features + metadata
- Stratified 5-fold cross-validation
- Test sets:
  - âœ… **Balanced test set (50/50)**: robust evaluation
  - âœ… **Real-world prevalence (~2%)**: realistic scenario simulation

### ğŸ¤– Deep Learning:
- **Framework**: TensorFlow / Keras
- **Architecture**: two-branch dense network with normalization
  - **Input 1**: PERG FFT features (RE + LE)
  - **Input 2**: Clinical metadata (age, sex)
  - Processed separately â†’ merged â†’ dense â†’ sigmoid output
- **Optimization**:
  - Loss: `binary_crossentropy`, metric: `AUC`
  - Callbacks: EarlyStopping, ReduceLROnPlateau, TensorBoard
- **Validation**: cross-validation + independent balanced test set
- **Threshold selection** based on:
  - ğŸ¯ Target sensitivity â‰¥ 0.8
  - ğŸ“Š Maximum F1-score
  - ğŸ“ˆ Youdenâ€™s index

---

## ğŸ“ˆ Results (Balanced Test Set)

| Model               | AUC     | Sensitivity | Specificity | F1-score | Accuracy | Threshold |
|---------------------|---------|-------------|-------------|----------|----------|-----------|
| ğŸ”¹ Random Forest     | **0.768** | 0.818       | 0.591       | 0.735    | **0.705** | 0.46      |
| ğŸ”¸ Deep Learning     | 0.660   | **1.000**   | 0.048       | **0.737**| 0.592    | 0.40      |

### ğŸ“Š DL Report (threshold = 0.40)

- **Sensitivity (Recall)**: 100.0%
- **Specificity**: 4.8%
- **Accuracy**: 59.2%
- **F1-score**: 0.7368
- **Positive class precision**: 58%

---

## ğŸ©º Clinical Interpretation

| Metric                    | DL Model (RE/LE + metadata) | ML Model (Random Forest)     |
|---------------------------|-----------------------------|-------------------------------|
| ğŸ”¬ Sensitivity            | âœ… Excellent (no missed cases) | Good (0.818)                 |
| ğŸ“‰ Specificity            | âŒ Very low (many false positives) | Better (0.591)          |
| ğŸ§  Interpretability       | Low (DL = black box)        | High (interpretable features) |
| ğŸ¥ Ideal Use Case         | Ultra-sensitive triage      | Balanced general screening    |

â¡ï¸ The **DL model** is useful as a **high-recall pre-screening tool**, detecting all pathological cases at the expense of high false positives.  
â¡ï¸ The **RF model** provides a more **balanced and interpretable** approach for general-purpose diagnostics.

---

## ğŸ“Š Threshold Analysis (DL)

```text
Threshold  Sensitivity  Specificity  F1-score   Accuracy
--------------------------------------------------------
0.10       1.0000       0.0000       0.7273     0.5714
0.20       1.0000       0.0476       0.7368     0.5918
0.30       1.0000       0.0476       0.7368     0.5918
0.35       1.0000       0.0000       0.7273     0.5714
0.40       1.0000       0.0476       0.7368     0.5918  âœ… Optimal threshold (F1 max)
0.45       0.9286       0.0952       0.7123     0.5714
0.50       0.7143       0.5238       0.6897     0.6327
0.55       0.3571       0.8095       0.4762     0.5510
0.60       0.1071       0.9524       0.1875     0.4694
0.65+      0.0000       1.0000       0.0000     0.4286



âœ… Bioinformatics Best Practices

| Practice                                 | Implemented |
| ---------------------------------------- | ----------- |
| ğŸ§ª Cross-validation + real-world testing | âœ…           |
| ğŸ“Š Full reports (ROC, confusion, F1)     | âœ…           |
| ğŸ“¦ Reproducible outputs (.npy, .csv)     | âœ…           |
| âš–ï¸ Class weighting for imbalance         | âœ…           |
| ğŸ” Custom threshold analysis             | âœ…           |
| ğŸ“ Git versioning & training logs        | âœ…           |
| ğŸ“ˆ TensorBoard visualization             | âœ…           |


âš ï¸ Limitations & Future Work


âŒ No external clinical validation

âŒ No real-time integration (EHR, PERG API)

âŒ Dataset limited in size and diversity

â— DL specificity remains low (risk of over-referral)



ğŸ§­ Future directions:


Multicenter prospective validation

Web interface or GUI integration

Training with sequential models (e.g. CNN, LSTM)

Signal quality control & artifact analysis


ğŸ“ References


PERG-IOBA â€“ PhysioNet (2024)

FDA SaMD GMLP Guidelines (2021)

ISO 14971 â€“ Risk Management in Medical Devices

Best Practices in ML for Biomedical Signal Analysis


ğŸ›‘ Disclaimer
This repository is a simulated bioinformatics project for educational purposes only.
It is not a certified medical device or diagnostic tool.
All clinical decisions must be validated by qualified healthcare professionals.

