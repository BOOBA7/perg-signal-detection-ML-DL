# perg-signal-detection-ml

# üß† D√©tection automatique d‚Äôalt√©ration du signal PERG via Machine Learning

## üéØ Objectif

Le but de ce projet est de simuler un **cas r√©el en bioinformatique m√©dicale** en d√©veloppant un pipeline complet de classification bas√© sur le signal PERG (Pattern Electroretinogram).  
Nous cherchons √† d√©tecter automatiquement si un signal est alt√©r√© ou non, en lien avec des pathologies ophtalmiques h√©r√©ditaires ou acquises, comme l‚Äôatrophie optique, la r√©tinopathie toxique ou la maladie de Stargardt.

---

## üß™ Donn√©es utilis√©es

- **Source** : [PERG-IOBA Dataset](https://physionet.org/content/perg-ioba-dataset/1.0.0/)
- **Contenu** :
  - Signaux bruts des deux yeux (`RE_1`, `LE_1`)
  - M√©tadonn√©es : √¢ge, sexe, diagnostic clinique
- **Label** :
  - `0` = signal normal
  - `1` = signal alt√©r√© associ√© √† une pathologie affectant le nerf optique ou la r√©tine

---

## üß¨ Extraction de features

Pour chaque ≈ìil (RE, LE), les features suivantes sont extraites :

- **Statistiques classiques** : moyenne, √©cart-type, min, max, amplitude
- **Moments statistiques** : asym√©trie (`skewness`), aplatissement (`kurtosis`)
- **Signaux cliniques** : amplitude et latence de P50 et N95
- **Analyse spectrale** : fr√©quence dominante FFT, √©nergie spectrale
- **Donn√©es d√©mographiques** : √¢ge, sexe (encod√©)

---

## ‚öôÔ∏è Mod√©lisation

### üìå M√©thodologie :

1. **S√©paration des donn√©es** :
   - Entra√Ænement sur un jeu √©quilibr√© (50 % positifs, 50 % n√©gatifs)
   - √âvaluation sur deux configurations :
     - ‚úÖ Jeu de test √©quilibr√© pour comparaison des mod√®les
     - üåç Jeu de test simulant la **pr√©valence r√©elle** (~2 %) pour √©valuation r√©aliste

2. **Validation crois√©e (5 folds)** :
   - Moyennes des performances calcul√©es pour chaque mod√®le

3. **Optimisation du seuil de d√©cision** :
   - Recherche d‚Äôun **seuil permettant une sensibilit√© ‚â• 0.8**
   - Crucial dans le domaine m√©dical pour √©viter les faux n√©gatifs

---

## üìà R√©sultats

### üîÅ Validation crois√©e (5-fold)

| Mod√®le              | Recall (mean) | F1-score (mean) | Balanced Acc (mean) | ROC AUC (mean) |
|---------------------|---------------|------------------|----------------------|----------------|
| Logistic Regression | 0.735         | 0.698            | 0.632                | 0.699          |
| Random Forest       | 0.698         | 0.687            | 0.637                | 0.697          |
| XGBoost             | 0.668         | 0.663            | 0.618                | 0.672          |
| Decision Tree       | 0.653         | 0.630            | 0.590                | 0.601          |

### üß™ √âvaluation sur jeu √©quilibr√© (test 50/50)

| Mod√®le              | Sensibilit√© | Sp√©cificit√© | F1-score | Balanced Acc | ROC AUC |
|---------------------|-------------|-------------|----------|---------------|----------|
| Logistic Regression | 0.773       | 0.591       | 0.708    | 0.682         | 0.727    |
| Random Forest       | 0.682       | 0.591       | 0.652    | 0.636         | 0.768    |
| XGBoost             | 0.591       | 0.545       | 0.578    | 0.568         | 0.680    |
| Decision Tree       | 0.636       | 0.455       | 0.583    | 0.545         | 0.545    |

### ü©∫ Ajustement du seuil pour Recall ‚â• 0.8

| Mod√®le              | Seuil  | Sensibilit√© | Sp√©cificit√© | F1-score | Balanced Acc | AUC     |
|---------------------|--------|-------------|--------------|----------|----------------|---------|
| Random Forest       | 0.46   | 0.818       | 0.591        | 0.735    | 0.705          | 0.768   |
| Logistic Regression | 0.42   | 0.818       | 0.409        | 0.679    | 0.614          | 0.727   |
| XGBoost             | 0.25   | 0.818       | 0.364        | 0.667    | 0.591          | 0.680   |

---

## üìä Analyse des matrices de confusion

Chaque mod√®le a √©t√© √©valu√© sur un test √©quilibr√© avec 50 % de cas positifs :


üìç Exemple - Random Forest
TP = 27 | FN = 6 | TN = 23 | FP = 10
