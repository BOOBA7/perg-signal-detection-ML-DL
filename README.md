# perg-signal-detection-ml

# ğŸ§  DÃ©tection automatique dâ€™altÃ©ration du signal PERG via Machine Learning

## ğŸ¯ Objectif

Le but de ce projet est de simuler un **cas rÃ©el en bioinformatique mÃ©dicale** en dÃ©veloppant un pipeline complet de classification basÃ© sur le signal PERG (Pattern Electroretinogram).  
Nous cherchons Ã  dÃ©tecter automatiquement si un signal est altÃ©rÃ© ou non, en lien avec des pathologies ophtalmiques hÃ©rÃ©ditaires ou acquises, comme lâ€™atrophie optique, la rÃ©tinopathie toxique ou la maladie de Stargardt.

---

## ğŸ§ª DonnÃ©es utilisÃ©es

- **Source** : [PERG-IOBA Dataset](https://physionet.org/content/perg-ioba-dataset/1.0.0/)
- **Contenu** :
  - Signaux bruts des deux yeux (`RE_1`, `LE_1`)
  - MÃ©tadonnÃ©es : Ã¢ge, sexe, diagnostic clinique
- **Label** :
  - `0` = signal normal
  - `1` = signal altÃ©rÃ© associÃ© Ã  une pathologie affectant le nerf optique ou la rÃ©tine

---

## ğŸ§¬ Extraction de features

Pour chaque Å“il (RE, LE), les features suivantes sont extraites :

- **Statistiques classiques** : moyenne, Ã©cart-type, min, max, amplitude
- **Moments statistiques** : asymÃ©trie (`skewness`), aplatissement (`kurtosis`)
- **Signaux cliniques** : amplitude et latence de P50 et N95
- **Analyse spectrale** : frÃ©quence dominante FFT, Ã©nergie spectrale
- **DonnÃ©es dÃ©mographiques** : Ã¢ge, sexe (encodÃ©)

---

## âš™ï¸ ModÃ©lisation

### ğŸ“Œ MÃ©thodologie :

1. **SÃ©paration des donnÃ©es** :
   - EntraÃ®nement sur un jeu Ã©quilibrÃ© (50 % positifs, 50 % nÃ©gatifs)
   - Ã‰valuation sur deux configurations :
     - âœ… Jeu de test Ã©quilibrÃ© pour comparaison des modÃ¨les
     - ğŸŒ Jeu de test simulant la **prÃ©valence rÃ©elle** (~2 %) pour Ã©valuation rÃ©aliste

2. **Validation croisÃ©e (5 folds)** :
   - Moyennes des performances calculÃ©es pour chaque modÃ¨le

3. **Optimisation du seuil de dÃ©cision** :
   - Recherche dâ€™un **seuil permettant une sensibilitÃ© â‰¥ 0.8**
   - Crucial dans le domaine mÃ©dical pour Ã©viter les faux nÃ©gatifs

---

## ğŸ“ˆ RÃ©sultats

### ğŸ” Validation croisÃ©e (5-fold)

| ModÃ¨le              | Recall (mean) | F1-score (mean) | Balanced Acc (mean) | ROC AUC (mean) |
|---------------------|---------------|------------------|----------------------|----------------|
| Logistic Regression | 0.735         | 0.698            | 0.632                | 0.699          |
| Random Forest       | 0.698         | 0.687            | 0.637                | 0.697          |
| XGBoost             | 0.668         | 0.663            | 0.618                | 0.672          |
| Decision Tree       | 0.653         | 0.630            | 0.590                | 0.601          |

### ğŸ§ª Ã‰valuation sur jeu Ã©quilibrÃ© (test 50/50)

| ModÃ¨le              | SensibilitÃ© | SpÃ©cificitÃ© | F1-score | Balanced Acc | ROC AUC |
|---------------------|-------------|-------------|----------|---------------|----------|
| Logistic Regression | 0.773       | 0.591       | 0.708    | 0.682         | 0.727    |
| Random Forest       | 0.682       | 0.591       | 0.652    | 0.636         | 0.768    |
| XGBoost             | 0.591       | 0.545       | 0.578    | 0.568         | 0.680    |
| Decision Tree       | 0.636       | 0.455       | 0.583    | 0.545         | 0.545    |

### ğŸ©º Ajustement du seuil pour Recall â‰¥ 0.8

| ModÃ¨le              | Seuil  | SensibilitÃ© | SpÃ©cificitÃ© | F1-score | Balanced Acc | AUC     |
|---------------------|--------|-------------|--------------|----------|----------------|---------|
| Random Forest       | 0.46   | 0.818       | 0.591        | 0.735    | 0.705          | 0.768   |
| Logistic Regression | 0.42   | 0.818       | 0.409        | 0.679    | 0.614          | 0.727   |
| XGBoost             | 0.25   | 0.818       | 0.364        | 0.667    | 0.591          | 0.680   |

---

## ğŸ“Š Analyse des matrices de confusion

Chaque modÃ¨le a Ã©tÃ© Ã©valuÃ© sur un test Ã©quilibrÃ© avec 50 % de cas positifs :


ğŸ“ Exemple - Random Forest
TP = 27 | FN = 6 | TN = 23 | FP = 10


---

## ğŸ’¡ Remarques bioinformatiques

- ğŸ”¬ Le choix dâ€™un **seuil adaptÃ©** est fondamental en santÃ© : on privilÃ©gie une **haute sensibilitÃ©** (ne pas rater de patients malades).
- ğŸŒ Lâ€™Ã©valuation finale respecte aussi une **prÃ©valence rÃ©aliste (~2%)**, permettant dâ€™estimer les performances en conditions rÃ©elles.
- ğŸ“ Ce projet nâ€™a pas pour but dâ€™atteindre un modÃ¨le cliniquement validÃ©, mais de **montrer un pipeline rigoureux** en apprentissage supervisÃ© appliquÃ© Ã  des donnÃ©es mÃ©dicales.

---

## âœ… Conclusion

Ce projet dÃ©montre lâ€™applicabilitÃ© du machine learning pour lâ€™analyse de signaux Ã©lectrophysiologiques.  
Il illustre un **cas dâ€™usage complet** allant de lâ€™extraction de features Ã  lâ€™Ã©valuation rigoureuse, avec un focus sur les contraintes propres Ã  la **bioinformatique mÃ©dicale**.
