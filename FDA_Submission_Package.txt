```markdown
# üßæ FDA SUBMISSION PACKAGE ‚Äì SIMULATED
## Software as a Medical Device (SaMD)
### Title: PERG Signal Classifier via ML & DL
**Author**: Anis Boubala  
**Date**: July 2025

---

## 1. DEVICE OVERVIEW
**Device Name**: PERG Signal Classifier  
**Type**: Software as a Medical Device (SaMD)  
**Indication for Use**:
> To support ophthalmologists in detecting alterations in pattern electroretinogram (PERG) signals, potentially indicative of early-stage retinal or optic nerve dysfunction (e.g., glaucoma).

**Device Description**:
A software-based tool for binary classification of PERG electrophysiological signals (RE_1, LE_1), developed using:
- Classical machine learning (ML) models trained on FFT-derived features and clinical metadata.
- Deep learning (DL) models leveraging raw concatenated signals and patient metadata.

**Output**: Binary prediction ‚Äî `"Normal PERG"` or `"Altered PERG"`

---

## 2. INTENDED USE
- **Target Population**: Adults aged 18‚Äì90 undergoing PERG testing.  
- **Intended Environment**: Ophthalmology clinics and vision screening centers.  
- **Intended Users**: Ophthalmologists or trained technicians.  
- **Device Role**: Clinical decision support (CDS); not a standalone diagnostic tool.  
- **Limitations**: Research-only prototype; not FDA-cleared. Requires confirmatory clinical evaluation.

---

## 3. DATA & LABELING
**Dataset**: PERG-IOBA Dataset (sourced from PhysioNet)  
**Total Labeled Samples**: 279 patient records  
**Signal Channels**: RE_1, LE_1 (sampled at 300 Hz, microvolt resolution)  
**Metadata**: Age, sex, and clinical diagnosis  
**Reference Standard**: Expert clinical review documented in `metadata_clinical.csv`

---

## 4. MODELS EVALUATED
**Classical Machine Learning**:
- Logistic Regression
- Decision Tree
- Random Forest (**best classical performer**)
- XGBoost

**Deep Learning**:
- Multilayer fully connected network (Keras / TensorFlow)
- Inputs: Concatenated FFT features + metadata
- Architecture: Dense layers with Dropout and Batch Normalization (3‚Äì4 layers)

**Thresholding Approaches**:
- **Youden Index**: Maximizes (Sensitivity + Specificity ‚Äì 1)
- **F1-maximizing threshold**: Prioritizes balance between recall and precision

---

## 5. PERFORMANCE SUMMARY
| Model Type         | AUC    | Recall | Specificity | F1-Score | Accuracy | Threshold     |
|--------------------|--------|--------|-------------|----------|----------|---------------|
| Random Forest (ML) | **0.768** | 0.70   | 0.70        | 0.69     | **0.71**   | 0.50 (default) |
| Deep Learning       | 0.660  | **0.93** | 0.33        | **0.76** | 0.67     | 0.45 (F1-opt)  |

**Interpretation**:
- The **Random Forest** model offers a strong balance of sensitivity and specificity, reflected by the highest AUC and overall accuracy.
- The **Deep Learning** model demonstrates superior sensitivity, suitable for early detection or screening purposes, but has lower specificity.

---

## 6. GOOD MACHINE LEARNING PRACTICES (GMLP)
- ‚úÖ Stratified and balanced training/test splits
- ‚úÖ Explainable input features (FFT statistics + metadata)
- ‚úÖ Transparent DL architecture with documented training parameters
- ‚úÖ ROC-based threshold tuning and validation metrics
- ‚úÖ Version control (Git), seed fixing, and reproducible pipeline (requirements.txt)
- ‚úÖ Reference standard validated via ophthalmologist-confirmed clinical tags

---

## 7. VALIDATION STRATEGY
- **Cross-validation**: Stratified 5-fold on training set
- **Hold-out test sets**:
  - Balanced 50/50 (pathological/control)
  - Realistic prevalence (~2%)
- Evaluation metrics: ROC-AUC, confusion matrices, precision-recall curves
- Documented threshold selection strategy and reproducible visualizations

---

## 8. RISK ANALYSIS (Based on ISO 14971)
| Risk Type                      | Mitigation Strategy                                      |
|-------------------------------|-----------------------------------------------------------|
| ‚ùå False Negatives (missed diagnosis) | High-sensitivity threshold tuning (TPR ‚â• 0.90)             |
| ‚ö†Ô∏è False Positives (unnecessary follow-up) | Interpretation by clinician; specificity metrics tracked   |
| ‚ö†Ô∏è Dataset Bias               | Stratified sampling; evaluation on realistic test split   |
| ‚ùå Overfitting (limited data) | Dropout layers, early stopping, cross-validation          |

---

## 9. LIMITATIONS
- Lack of prospective, multicenter external validation
- No integration with EHRs or external devices
- Signal quality variability not corrected for all noise/artifact types
- Model trained on pre-recorded data; no real-time acquisition yet
- Ground truth relies solely on clinical diagnosis tags in dataset

---

## 10. FUTURE WORK
- Initiate formal FDA pre-submission process (if commercialized)
- Conduct external validation in clinical and control populations
- Develop GUI or browser-based CDS tool for real-world use
- Enable real-time PERG acquisition via external device APIs
- Explore more robust DL architectures (e.g., CNNs, LSTMs, transformers)

---

## 11. DISCLAIMER
This document simulates a pre-submission to the FDA for academic and prototyping purposes only.  
The PERG classifier described herein is **not FDA-cleared**, and should **not be used in clinical decision-making**.  
Intended solely for research in bioinformatics and digital ophthalmology.
```

